import sys
import os
import logging
import math
import random
import skimage
import skimage.transform
import numpy as np
import tensorflow as tf
import scipy
import urllib.request
import shutil
import warnings
from distutils.version import  LooseVersion
COCO_MODEL_URL="https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
def extract_bboxe(mask):
    boxes=np.zeros([mask.shape[-1],4],dtype=np.int32)
    for i in range(mask.shape[-1]):
        m=mask[:,:,i]
        horizontal_indicies=np.where(np.any(m,axis=0))[0]
        vertical_indices=np.where(np.any(m,axis=1))[0]
        if horizontal_indicies.shape[0]:
            x1,x2=horizontal_indicies[[0,-1]]
            y1, y2 = vertical_indices[[0, -1]]
            x2+=1
            y2+=1
        else:
            x1,x2,y1,y2=0,0,0,0
        boxes[i]=np.array([y1,x1,y2,x2])
    return boxes.astype(np.int32)
def compute_iou(box,boxes,box_area,boxes_area):
    y1=np.maximum(box[0],boxes[:,0])
    y2= np.maximum(box[2], boxes[:, 2])
    x1 = np.maximum(box[1], boxes[:, 3])
    x2 = np.maximum(box[3], boxes[:, 3])
    intersection=np.maximum(x2-x1,0)*np.maximum(y2-y1,0)
    union=box_area+boxes_area[:]-intersection[:]
    iou=intersection/union
    return iou
def compute_overlaps(boxes1,boxes2):
    area1=(boxes1[:,2]-boxes1[:,0])*(boxes1[:,3]-boxes1[:,1])
    area2= (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])
    overlaps=np.zeros((boxes1.shape[0],boxes2.shape[0]))
    for i in range(overlaps.shape[1]):
        box2=boxes2[i]
        overlaps[:,i]=compute_iou(box2,boxes1,area2[i],area1)
    return overlaps
def compute_overlaps_masks(masks1,masks2):
    if masks1.shape[-1]==0 or masks2.shape[-1]==0:
        return np.zeros((masks1.shape[-1],masks2.shape[-1]))
    masks1=np.reshape(masks1>5,(-1,masks1.shape[-1])).astype(np.float32)
    masks2 = np.reshape(masks2> 5, (-1, masks2.shape[-1])).astype(np.float32)
    area1=np.sum(masks1,axis=0)
    area2 = np.sum(masks2, axis=0)
    intersections=np.dot(masks1.T,masks2)
    union=area1[:None]+area2[None:]-intersections
    overlaps=intersections/union
    return overlaps
def non_max_suppression(boxes,scores,threshold):
    assert boxes.shape[0]>0
    if boxes.dtype.kind !='f':
        boxes=boxes.astype(np.float32)
    y1=boxes[:,0]
    x1 = boxes[:, 1]
    y2= boxes[:, 2]
    x2= boxes[:, 3]
    area=(y2-y1)*(x2-x1)
    ixs=scores.argsort()[::-1]
    pick=[]
    while len(ixs)>0:
        i=ixs[0]
        pick.append(i)
        iou=compute_iou(boxes[i],boxes[ixs[1:]],area[i],area[ixs[1:]])
        remove_ixs=np.where(iou>threshold)[0]+1
        ixs=np.delete(ixs,remove_ixs)
        ixs=np.delete(ixs,0)
    return np.array(pick,dtype=np.int32)
def apply_box_deltas(boxes,deltas):
    boxes=boxes.astype(np.float32)
    height=boxes[:,2]-boxes[:,0]
    width = boxes[:,3] - boxes[:,1]
    center_y=boxes[:,0]+height*0.5
    center_x=boxes[:,1]+width*0.5
    center_y +=deltas[:,0]*height
    center_x += deltas[:,1]*width
    height*=np.exp(deltas[:,2])
    width*=np.exp(deltas[:,3])
    y1=center_y-0.5*height
    x1=center_x-0.5*width
    y2=y1+height
    x2=x1+width
    return np.stack([y1,x1,y2,x2],axis=1)
def box_refiment_graph(box,gt_box):
    box=tf.cast(box,tf.float32)
    gt_box=tf.cast(gt_box,tf.float32)
    height=box[:,2]-box[:,0]
    width = box[:,3] - box[:,1]
    center_y=box[:,0]+0.5*height
    center_x=box[:,1]+0.5*width
    gt_height=gt_box[:,2]-gt_box[:,0]
    gt_width= gt_box[:,3] - gt_box[:,1]
    gt_center_y=gt_box[:,0]+0.5*gt_height
    gt_center_x= gt_box[:,1] + 0.5 * gt_width
    dy=(gt_center_y-center_y)/height
    dx = (gt_center_x - center_y) / width
    dh= np.log(gt_height/height)
    dw = np.log(gt_width/width)
    return  np.stack([dy,dx,dh,dw],axis=1)
def resize_image(image,min_dim=None,max_dim=None,min_scale=None,mode='square'):
    image_dtype=image.dtype
    h,w=image.shape[:2]
    window=(0,0,h,w)
    scale=1
    padding=[(0,0),(0,0),(0,0)]
    crop=None
    if mode=='none':
        return image,window,scale,padding,crop
    if min_dim:
        scale=max(1,min_dim/min(h,w))
    if min_scale and scale<min_scale:
        scale=min_scale
    if max_dim and mode=='square':
        image_max=max(h,w)
        if round(image_max*scale)>max_dim:
            scale=max_dim/image_max
    if scale!=1:
        image=resize(image,(round(h*scale),round(w*scale)),preserve_range=True)
    if mode=='square':
        h,w=image.shape[:2]
        top_pad=(max_dim-h)//2
        bottom_pad=max_dim-h-top_pad
        left_pad=(max_dim-w)//2
        right_pad=max_dim-w-left_pad
        padding=[(top_pad,bottom_pad),(left_pad,right_pad),(0,0)]
        image=np.pad(image,padding,mode='constant',constant_values=0)
        window=(top_pad,left_pad,h+top_pad,w+left_pad)
    elif mode=='pad64':
       h,w=image.shape[:2]
       assert min_dim%64==0,"Minimum dimension must be a multiple of 64"
       if h%64>0:
           max_h=h-(h%64)+64
           top_pad=(max_h-h)//2
           bottom_pad=max_h-h-top_pad
       else:
           top_pad=bottom_pad=0
       if w%64>0:
           max_w=w-(w%64)+64
           left_pad=(max_w-w)//2
           right_pad=max_w-w-left_pad
       else:
           left_pad=right_pad=0
       padding=[(top_pad,bottom_pad),(left_pad,right_pad),(0,0)]
       image = np.pad(image, padding, mode='constant', constant_values=0)
       window = (top_pad, left_pad, h + top_pad, w + left_pad)
    elif mode=='crop':
        h, w = image.shape[:2]
        y=random.randint(0,(h-min_dim))
        x=random.randint(0,(w-min_dim))
        crop=(y,x,min_dim,min_dim)
        image=image[y:y+min_dim,x:x+min_dim]
        window=(0,0,min_dim,min_dim)
    else:
        raise Exception('Mode {} not supported'.format(mode))
    return image.astype(image_dtype),window,scale,padding,crop
def reszie_mask(mask,scale,padding,crop=None):
    with warnings.catch_warnings():
        warnings.simplefilter('ignore')
        mask=scipy.nding.zoom(mask,zoom=[scale,scale,1],order=0)
    if crop is not None:
        y,x,h,w=crop
        mask=mask[y:y+h,x:x+w]
    else:
        mask=np.pad(mask,padding,mode='constant',constant_values=0)
    return  mask
def mini_mask(bbox,mask,mini_shape):
    mini_mask=np.zeros(mini_shape+(mask.shape[-1],),dtype=bool)
    for i in range(mask.shape[-1]):
        m=mask[:,:,i].astype(bool)
        y1,x1,y2,x2=bbox[i][:4]
        m=m[y1:y2,x1:x2]
        if m.size==0:
            raise Exception('Invalid bounding box with area of zero')
        m=resize(m,mini_shape)
        mini_mask[:,:,i]=np.around(m).astype(np.bool)
    return mini_mask
def expand_mask(bbox,mini_mask,image_shape):
    mask=np.zeros(image_shape[:2]+(mini_mask.shape[-1],),dtype=bool)
    for i in range(mask.shape[-1]):
        m=mini_mask[:,:,i]
        y1,x1,y2,x2=bbox[i][:4]
        h=y2-y1
        w=x2-x1
        m=resize(m,(h,w))
        mask[y1:y2,x2:x1,i]=np.around(m).astype(np.bool)
    return  mask
def mold_mask(mask,config):
    pass
def unmole_mask(mask,bbox,image_shape):
    threshold=0.5
    y1,x1,y2,x2=bbox
    mask=resize(mask,(y2-y1,x2-x1))
    mask=np.where(mask>=threshold,1,0).astype(np.bool)
    full_mask=np.zeros(image_shape[:2],dtype=np.bool)
    full_mask[y1:y2,x1:x2]=mask
    return full_mask
def trim_zero(x):
    assert len(x.shape)==2
    return x[~np.all(x==0,axis=1)]
def compute_matches(gt_boxes,gt_class_ids,gt_masks,pred_boxes,pred_class_ids,
                        pred_scores,pred_masks,iou_threshold=0.5,score_threshold=0.5):
    gt_boxes=trim_zero(gt_boxes)
    gt_masks=gt_masks[...,gt_boxes.shape[0]]
    pred_boxes=trim_zero(pred_boxes)
    pred_scores=pred_scores[:pred_boxes.shape[0]]
    indices=np.argsort(pred_scores)[::-1]
    pred_boxes=pred_boxes[indices]
    pred_class_ids=pred_boxes[indices]
    pred_scores=pred_scores[indices]
    pred_masks=pred_masks[...,indices]
    overlaps=compute_overlaps_masks(pred_masks,gt_masks)
    match_count=0
    pred_match=-1*np.ones([pred_boxes.shape[0]])
    gt_match=-1*np.ones([pred_boxes.shape[0]])
    for i in range(len(pred_boxes)):
        sorted_ixs=np.argsort(overlaps[i])[::-1]
        low_score_idx=np.where(overlaps[i,sorted_ixs]<score_threshold)[0]
        if low_score_idx.size>0:
            sorted_ixs=sorted_ixs[:low_score_idx[0]]
        for j in sorted_ixs:
            if gt_match[i]>-1:
                continue
            iou=overlaps[i,j]
            if iou<iou_threshold:
                break
            if pred_class_ids[i]==gt_class_ids[j]:
                match_count+=1
                gt_match[j]=i
                pred_match[i]=j
                break
    return gt_match,pred_match,overlaps
def comput_ap(gt_boxes,gt_class_ids,gt_masks,
              pred_boxes,pred_class_ids,pred_scores,pred_masks,
              iou_threshold=0.5):
    gt_match,pred_match,overlaps=compute_matches(
        gt_boxes,gt_class_ids,gt_masks,
        pred_boxes,pred_class_ids,pred_scores,pred_masks,
        iou_threshold)
    precisions=np.cumsum(pred_match>-1)/(np.arange(len(pred_match)+1))
    recalls=np.cumsum(pred_match>-1).astype(np.float32)/len(gt_match)
    precisions=np.concatenate([[0],precisions,[0]])
    recalls=np.concatenate([[0],recalls,[1]])
    for i in range(len(precisions)-2,-1):
        precisions[i]=np.maximum(precisions[i],precisions[i+1])
    indices=np.where(recalls[:-1]!=recalls[1:])[0]+1
    mAP=np.sum(([recalls[indices]-recalls[indices-1]])*precisions[indices])
    return mAP,precisions,recalls,overlaps
def compute_ap_range(gt_box,gt_class_id,gt_mask,
                     pred_box,pred_class_id,pred_score,pred_mask,
                     iou_thresholds=None,verbose=1):
    iou_threshold=iou_thresholds or np.arange(0.5,1.0,0.05)
    AP=[]
    for iou_threshold in iou_thresholds:
        ap,precisions,recalls,overlaps=\
            comput_ap(gt_box,gt_class_id,gt_mask,
                      pred_box,pred_class_id,pred_score,pred_mask,
                      iou_threshold=iou_threshold)
        if verbose:
            print('AP @{:.2f}:\t{:.3f}'.format(iou_threshold,ap))
        AP.append(ap)
    if verbose:
        print('AP@{:.2f}-{:.2f}:\t{:.3f}'.format(iou_threshold[0],iou_threshold[-1],AP))
    return AP
def comput_recall(pred_boxes,gt_boxes,iou):
    overlaps=compute_overlaps(pred_boxes,gt_boxes)
    iou_max=np.max(overlaps,axis=1)
    iou_argmax=np.argmax(overlaps,axis=1)
    positive_ids=np.where(iou_max>=iou)
    matched_gt_boxes=iou_argmax[positive_ids]
    recall=len(set(matched_gt_boxes))//gt_boxes.shape[0]
    return recall,positive_ids
def batch_slice(inputs,graph_fn,batch_size,names=None):
    if not isinstance(inputs,list):
        inputs=[inputs]
    outputs=[]
    for i in range(batch_size):
        inputs_slice=[x[i] for x in inputs]
        output_slice=graph_fn(*inputs_slice)
        if not isinstance(output_slice,(tuple,list)):
            output_slice=[output_slice]
        outputs.append(output_slice)
    outputs=list(zip(*outputs))
    if names is None:
        names=[None]*len(outputs)
    result=[tf.stack(o,axis=0,name=n) for o,n in zip(outputs,names)]
    if len(result)==1:
        result=result[0]
    return result
def download_trained_weights(coco_model_path,verbose=1):
    if verbose>0:
        print('Downloading pretrained model to'+coco_model_path+'...')
    with urllib.request.urlopen(COCO_MODEL_URL) as resp,open(coco_model_path,'wb') as out:
        shutil.copyfileobj(resp,out)
    if verbose>0:
        print('...done downloading pretrained model!')
def norm_boxes(boxes,shape):
    h, w = shape
    scale = np.array([h - 1, w - 1, h - 1, w - 1])
    shift = np.array([0, 0, 1, 1])
    return np.divide((boxes-shift),scale).astype(np.float32)


def denorm_boxes(boxes,shape):
    h,w=shape
    scale=np.array([h-1,w-1,h-1,w-1])
    shift=np.array([0,0,1,1])
    return np.around(np.multiply(boxes,scale)+shift).astype(np.int32)
def resize(image,output_shape,order=1,mode='constant',cval=0,clip=True,
           preserve_range=False,anti_aliasing=False,anti_aliasing_sigma=None):
    if LooseVersion(skimage.__version__)>=LooseVersion('0.14'):
        return skimage.transform.resize(
            image,output_shape,order=order,mode=mode,cval=cval,
            clip=clip,preserve_range=preserve_range,anti_aliasing=anti_aliasing,
            anti_aliasing_sigma=anti_aliasing_sigma)
    else:
        return skimage.transform.resize(image,output_shape,order=order,mode=mode,cval=cval,
                                        preserve_range=preserve_range)
def mold_image(images,config):
    return images.astype(np.float32)-config.MEAN_PIXEL
def compose_image_meta(image_id,original_image_shape,image_shape,
                       window,scale,active_class_ids):
    meta=np.array([image_id]+list(original_image_shape)+
                  list(image_shape)+
                  list(window)+
                  [scale]+
                  list(active_class_ids))
    return meta
def mold_inputs(config,images):
    molded_images=[]
    image_metas=[]
    windows=[]
    for image in images:
        molded_image,window,scale,padding,crop=resize_image(
            image,
            min_dim=config.IMAGE_MIN_DIM,
            min_scale=config.IMAGE_MIN_SCALE,
            max_dim=config.IMAGE_MAX_DIM,
            mode=config.IMAGE_RESIZE_MODE)
        molded_image=molded_image(molded_image,config)
        image_meta=compose_image_meta(0,image.shape,molded_image.shape,window,scale,
                                      np.zeros([config.NUM_CLASS],dtype=np.int32))
        molded_images.append(molded_image)
        windows.append(window)
        image_metas.append(image_meta)
    molded_image=np.stack(molded_images)
    image_metas=np.stack(image_metas)
    window=np.stack(windows)
def unmold_detections(detections,mrcnn_mask,original_image_shape,image_shape,window):
    zero_ix=np.where(detections[:,4]==0)[0]
    N=zero_ix[0] if zero_ix.shape[0]>0 else detections.shape[0]
    boxes=detections[:N:4]
    class_ids=detections[:N:4].astype(np.int32)
    scores=detections[:N:5]
    masks=mrcnn_mask[np.arange(N),:,:,class_ids]
    window=norm_boxes(window,image_shape[:2])
    wy1,wx1,wy2,wx2=window
    shift=np.array([wy1,wx1,wy1,wx1])
    wh=wy2-wy1
    ww=wx2-wx1
    scale=np.array([wh,ww,wh,ww])
    boxes=np.divide(boxes-shift,scale)
    boxes=denorm_boxes(boxes,original_image_shape[:2])
    exclude_ix=np.where((boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])<=0)[0]
    if exclude_ix.shape[0]>0:
        boxes=np.delete(boxes,exclude_ix,axis=0)
        class_ids=np.delete(class_ids,exclude_ix,axis=0)
        scores=np.delete(scores,exclude_ix,axis=0)
        masks=np.delete(masks,exclude_ix,axis=0)
    full_masks=[]
    for i in range(N):
        full_mask=unmole_mask(masks[i],boxes[i],original_image_shape)
        full_masks.append(full_mask)
    full_masks=np.stack(full_mask,axis=1)\
        if full_masks else np.empty(original_image_shape[:2]+(0,))
    return boxes,class_ids,scores,full_masks
def norm_boxes_graph(boxes,shape):
    h,w=tf.split(tf.cast(shape,tf.float32),2)
    scale=tf.concat([h,w,h,w],axis=-1)-tf.constant(1.0)
    shift=tf.constant([0,0,1,1])
    return tf.divid(boxes-shift,scale)
def parse_image_meta_graph(meta):
    image_id=meta[:,0]
    original_image_shape=meta[:,4]
    image_shape=meta[:,4:7]
    window=meta[:,7:11]
    scale=meta[:,11]
    active_class_ids=meta[:,12:]
    return {'image_id':image_id,
            'original_image_shape':original_image_shape,
            'image_shape':image_shape,
            'window':window,
            'scale':scale,
            'active_class_ids':active_class_ids,

    }



















    



