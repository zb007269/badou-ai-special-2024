import tensorflow as tf
import keras.backend as K
import random
import numpy as np
import logging
from utils import utils
from utils.anchors import compute_backbone_shape,generate_pyraimd_anchors
def batch_pack_graph(x,counts,num_rows):
    outputs=[]
    for i in range(num_rows):
        outputs.append(x[i,counts[i]])
    return tf.concat(outputs,axis=0)
def smooth_l1_loss(y_true,y_pred):
    diff=K.abs(y_true-y_pred)
    less_than_one=K.cast(K.less(diff,1.0),'float32')
    loss=(less_than_one*0.5*diff**2)+(1-less_than_one)*(diff-0.5)
    return loss
def rpn_class_loss_graph(rpn_math,rpn_class_logits):
    rpn_math=tf.squeeze(rpn_math,-1)
    anchor_class=K.cast(K.equal(rpn_math,1),tf.int32)
    indices=tf.where(K.not_equal(rpn_math,0))
    rpn_class_logits=tf.gather_nd(rpn_class_logits,indices)
    anchor_class=tf.gather_nd(anchor_class,indices)
    loss=K.sparse_categorical_crossentropy(target=anchor_class,
                                           output=rpn_class_logits,
                                           from_logits=True)
    loss=K.switch(tf.size(loss)>0,K.mean(loss),tf.concat(0.0))
    return  loss
def rpn_bbox_loss_graph(conifg,target_bbox,rpn_match,rpn_bbox):
    rpn_match=K.squeeze(rpn_match,-1)
    inidces=tf.where(K.equal(rpn_match,1))
    rpn_bbox=tf.gather_nd(rpn_bbox,inidces)
    batch_counts=K.sum(K.cast(K.equal(rpn_match,1),tf.int32),axis=1)
    target_bbox=batch_pack_graph(target_bbox,batch_counts,conifg.IMAGE_PER_GPU)
    loss=smooth_l1_loss(target_bbox,rpn_bbox)
    loss=K.switch(tf.size(loss)>0,K.mean(loss),tf.constant(0.0))
    return loss
def mrcnn_class_loss_graph(tagart_class_ids,pred_class_logits,active_class_ids):
    tagart_class_ids=tf.cast(tagart_class_ids,'int64')
    pred_class_ids=tf.argmax(pred_class_logits,axis=2)
    pred_active=tf.gather(active_class_ids[0],pred_class_ids)
    loss=tf.nn.sparse_softmax_cross_entropy_with_logits(
        labels=tagart_class_ids,logits=pred_class_logits)
    loss=loss*pred_active
    loss=tf.reduce_sum(loss)/tf.reduce_sum(pred_active)
    return loss
def mcrnn_bbox_loss_graph(target_bbox,target_class_ids,pred_bbox):
    target_class_ids=K.reshape(target_class_ids,(-1,))
    target_bbox=K.reshape(target_bbox,(-1,4))
    pred_bbox=K.reshape(pred_bbox,(-1,K.int_shape(pred_bbox)[2],4))
    positive_roi_ix=tf.where(target_class_ids>0)[:,0]
    positive_roi_class_ids=tf.cast(tf.gather(target_class_ids,positive_roi_ix),tf.int64)
    indices=tf.stack([positive_roi_ix,positive_roi_class_ids],axis=1)
    target_bbox=tf.gather(target_bbox,positive_roi_ix)
    pred_bbox=tf.gather_nd(pred_bbox,indices)
    loss=K.switch(tf.size(target_bbox)>0,
                  smooth_l1_loss(y_true=target_bbox,y_pred=pred_bbox),
                  tf.constant(0.0))
    loss=K.mean(loss)
    return loss
def mrcnn_mask_loss_graph(taget_masks,target_class_ids,pred_masks):
    target_class_ids=K.reshape(target_class_ids,(-1,))
    mask_shape=tf.shape(taget_masks)
    taget_masks=K.reshape(taget_masks,(-1,mask_shape[2],mask_shape[3]))
    pred_shape=tf.shape(pred_masks)
    pred_masks=K.reshape(pred_masks,(-1,pred_shape[2],pred_shape[3],pred_shape[4]))
    pred_masks=tf.transpose(pred_masks,[0,3,1,2])
    positive_ix=tf.where(target_class_ids>0)[:,0]
    positive_class_ids=tf.cast(tf.gather(target_class_ids,pred_masks),tf.int64)
    indices=tf.stack([positive_roi_ix,positive_roi_class_ids],axis=1)
    y_true=tf.gather(taget_masks,positive_ix)
    y_pred=tf.gather_nd(pred_masks,indices)
    loss=K.switch(tf.size(target_bbox)>0,
                  K.binary_crossentropy(target=y_true,output=y_pred),
                  tf.constant(0.0))
    loss=K.mean(loss)
    return loss
def load_image_gt(dataset,config,image_id,augment=False,augmentation=None,use_mini_mask=False):
    image=dataset.load_image(image_id)
    mask,class_ids=dataset.load_mask(image_id)
    original_shape=image.shape
    image,window,scale,padding,crop=utils.resize_image(image,
                                                       min_dim=config.IMAGE_MIN_DIM,
                                                       min_scale=config.IMAGE_MIN_SCALE,
                                                       max_dim=config.IMAGE_MAX_DIM,
                                                       mode=config.IMAGE_RESZIZE_MODE)
    mask=utils.resize_mask(mask,scale,padding,crop)
    if augment:
        logging.warning("'augment' is deprecated.Use'augmentation'instead.")
        if random.randint(0,1):
            image=np.fliplr(image)
            mask=np.fliplr(mask)
    if augmentation:
        import imgaug
        MASK_AUGMENTERS=["Sequential", "SomeOf", "OneOf", "Sometimes",
                           "Fliplr", "Flipud", "CropAndPad",
                           "Affine", "PiecewiseAffine"]
        def hook(images,augmenter,parents,default):
            return augmenter.__class__.__name__ in MASK_AUGMENTERS
        image_shape=image.shape
        mask_shape=mask.shape
        det=augmentation.to_deterministic()
        image=det.augment_image(image)
        mask=det.augment_image(mask.astype(np.uint8),hooks=imgaug.HooksImage(activation=hook))
        assert image.shape==image_shape, "Augmentation shouldn't change image size"
        assert mask.shape==mask_shape,"Augmentation shouldn't change mask size"
        mask= mask.astype(np.bool)
        _idx=np.sum(mask,axis=(0,1))>0
        mask=mask[:,:,_idx]
        class_ids=class_ids[_idx]
        bbox=utils.extract_bboxes(mask)
        active_class_ids=np.zeros([dataset.num_classes],dtype=np.int32)
        source_class_ids=dataset.source_class_ids[dataset.image_info[image_id]['source']]
        active_class_ids[source_class_ids]=1
        if use_mini_mask:
            mask=utils.minimize_mask(bbox,mask,config.MIN_MASK_SHAPE)
        image_meta=utils.compose_image_meta(image_id,original_shape,image.shape,window,scale,active_class_ids)
        return image,image_meta,class_ids,bbox,mask
def build_rpn_targets(image_shape,anchors,gt_class_ids,gt_boxes,config):
    rpn_match=np.zeros([anchors.shape[0]],np.int32)
    rpn_bbox=np.zeros((config.RPN_TRAIN_ANCHORS_PER_IMAGE,4))
    crowd_ix=np.where(gt_class_ids<0)[0]
    if crowd_ix.shape[0]>0:
        non_crowd_ix=np.where(gt_class_ids>0)[0]
        crowd_boxes=gt_boxes[crowd_ix]
        gt_class_ids=gt_class_ids[non_crowd_ix]
        gt_boxes=gt_boxes[non_crowd_ix]
        crowd_overlaps=utils.compute_overlaps(anchors,crowd_boxes)
        crowd_iou_max=np.amax(crowd_overlaps,axis=1)
        no_crowd_bool=(crowd_iou_max<0.001)
    else:
        no_crowd_bool=np.ones([anchors.shape[0]],dtype=bool)
    overlaps=utils.compute_overlaps(anchors,gt_boxes)
    anchor_iou_argmax=np.argmax(overlaps,axis=1)
    anchor_iou_max=overlaps[np.arange(overlaps.shape[0]),anchor_iou_argmax]
    rpn_match[(anchor_iou_argmax<0.3)&(no_crowd_bool)]=-1
    gt_iou_argmax=np.where(overlaps==np.max(overlaps,axis=0))[:,0]
    rpn_match[gt_iou_argmax]=1
    rpn_match[anchor_iou_max>=0.7]=1
    ids=np.where(rpn_match==1)[0]
    extra=len(ids)-(config.RPN_TRAIN_ANCHORS_PER_IMAGE//2)
    if extra>0:
        ids=np.random.choice(ids,extra,replace=False)
        rpn_match[ids]=0
    ids=np.where(rpn_match==-1)[0]
    extra=len(ids)-(config.RPN_TRAIN_ANCHORS_PER_IMAGE-np.sum(rpn_match==1))
    if extra > 0:
        ids = np.random.choice(ids, extra, replace=False)
        rpn_match[ids] = 0
    ids=np.where(rpn_match==1)[0]
    ix=0
    for i ,a in zip(ids,anchors[ids]):
        gt=gt_boxes[anchor_iou_argmax[i]]
        gt_h=gt[2]-gt[0]
        gt_w= gt[3] - gt[1]
        gt_center_y = gt[0]+0.5*gt_h
        gt_center_x = gt[1] + 0.5 * gt_w
        a_h = a[2] - a[0]
        a_w = a[3] - a[1]
        a_center_y = a[0] + 0.5 * a_h
        a_center_x = gt[1] + 0.5 * a_w
        rpn_bbox[ix]=[
            (gt_center_y-a_center_y)/a_h,
            (gt_center_x - a_center_x) / a_w,
            np.log(gt_h/a_h),
            np.log(gt_w/a_w),]
        rpn_bbox[ix]/=config.RPN_BBOX_STD_DEV
        ix+=1
    return  rpn_match,rpn_bbox
def data_generator(dataset,config,shuffle=True,augment=False,augmentation=None,
                   batch_size=1,detection_targets=False,
                   no_augmentation_sources=None):
    b=0
    image_index=-1
    image_ids=np.copy(dataset.image_ids)
    no_augmentation_sources=no_augmentation_sources or []
    backbone_shapes=compute_backbone_shape(config,config.IMAGE_SHAPE)
    anchors=generate_pyraimd_anchors(config.PRN_AHCOR_SCLAES,
                                     config.PRN_AHCOR_RATIOS,
                                     backbone_shapes,
                                     config.BACKBONE_STRIDES,
                                     config.PRN_AHCOR_STRIDE)
    while True:
        image_index=(image_index+1)%len(image_ids)
        if shuffle and image_index==0:
            np.random.shuffle(image_ids)
        image_id=image_ids[image_index]
        if dataset.image_info[image_id]['source'] in no_augmentation_sources:
            image,image_meta,gt_class_ids,gt_boxes,gt_masks=\
                load_image_gt(dataset,config,image_id,augment=augment,
                              augmentation=None, use_mini_mask=config.USE_MINI_MASK)
        else:
            image, image_meta, gt_class_ids, gt_boxes, gt_masks = \
                load_image_gt(dataset, config, image_id, augment=augment,
                              augmentation=augmentation, use_mini_mask=config.USE_MINI_MASK)
        if not np.any(gt_class_ids>0):
            continue
        rpn_match,rpn_bbox=build_rpn_targets(image.shape,anchors,gt_class_ids,
                                             gt_boxes,config)
        if gt_boxes.shape[0]>config.MAX_GT_INSTANCES:
            ids=np.random.choice(
                np.arange(gt_boxes.shape[0]),config.MAX_GT_INSTANCES,replace=False)
            gt_class_ids=gt_class_ids[ids]
            gt_boxes=gt_boxes[ids]
            gt_masks=gt_masks[ids]
        if b==0:
            batch_image_meta=np.zeros(
                (batch_size,)+image_meta.shape,dtype=image_meta.dtype)
            batch_rpn_match=np.zeros(
                [batch_size,anchors.shape[0],1],dtype=rpn_match.dtype)
            batch_rpn_bbox=np.zeros(
                [batch_size,config.RPN_TRAIN_ANCHORS_PER_IMAGE,4],dtype=rpn_bbox.dtype)
            batch_images=np.zeros(
                (batch_size,)+image.shape,dtype=np.float32)
            batch_gt_class_ids=np.zeros(
                (batch_size,config.MAX_GT_INSTANCES),dtype=np.int32)
            batch_gt_boxes=np.zeros(
                (batch_size,config.MAX_GT_INSTANCES,4),dtype=np.int32)
            batch_gt_masks=np.zeros(
                (batch_size,gt_masks.shape[0],gt_masks[1],config.MAX_GT_INSTANCES),dtype=gt_masks.dtyepe)
        batch_image_meta[b]=image_meta
        batch_rpn_match[b]=rpn_match[:,np.newaxis]
        batch_rpn_bbox[b]=rpn_bbox
        batch_images[b]=utils.mold_image(image.astype(np.float32),config)
        batch_gt_class_ids[b,:gt_class_ids.shape[0]]=gt_class_ids
        batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes
        batch_gt_boxes[b, :,:,:gt_masks.shape[-1]] = gt_masks
        b+=1
        if b>=batch_size:
            inputs=[batch_images,batch_image_meta,batch_rpn_match,batch_rpn_bbox,
                    batch_gt_class_ids,batch_gt_boxes,batch_gt_masks]
            outputs=[]
            yield inputs,outputs
            b=0


















